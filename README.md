# Codify

Codify from Small Magellanic Cloud is a coding assistant which uses the latest advances in Deep Learning and Large Language Models. It follows your instructions and provides suggestions on where exactly and how it proposes to change your code. For more key features, keep reading.
## Features
- Supports 15+ programming languages
- State of the art model (for the size)
- Experimental code rewriting features
- Local inference
- Cloud inference
- We are crowdsourcing data for RLHF (the method behind GPT models)
- Don’t want your AI tools to be monopolized by big corporations? Support us on patreon.

## Installation
1. Install the extension
2. Click through the login option and follow it to [codify.smallcloud.ai](https://codify.smallcloud.ai); we recommend using login with Google or GitHub to avoid email verification.
3. Try out plugin.

## Getting started
You can see the “codify” status on the right bottom corner of the screen. The status will be updated when codify is communicating with the server.

On the left bar, you can see the new Codify panel. It lets you explore new features and shows the history of the requests you sent to Codify.

## How to use
To ask Codify to do something, press F1. It will ask you for your intent: what are you trying to do? Try "Add docstrings" or "Add type hints". 
Change suggestions provided by the model with another press on F1.

If you want to focus on a specific area of your code, just highlight it before asking Codify.

# Features
## Autocompletion
Accept suggestions about your next lines of code based on context & syntax both before and after the cursor.
## Highlight and Fix (beta)
Model highlights what is likely to change given an instruction. Click to generate changes. 
## Select And Refactor (beta)
Select specific code and tell the model what you want. 
## Settings
You can access the Codify Settings panel by going to the Extensions panel in VSCode, selecting the extension, and clicking on to Extension settings.

Codify settings allow you to 
- Enter your API key
- Choose Temperature for the model. Lower temperature guides the model to select higher probability words, whereas higher temperature allows it to provide more variable suggestions.